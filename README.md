# üß† LINE¬†RAG¬†API

_A retrieval‚Äëaugmented chatbot for LINE that helps insurance customers get concise answers from proprietary knowledge bases._

![FastAPI](https://img.shields.io/badge/Made%20with-FastAPI-009688?logo=fastapi&logoColor=white) ![Python](https://img.shields.io/badge/Python-3.10%2B-blue?logo=python) ![Chatbot](https://img.shields.io/badge/RAG%20Chatbot-LLM%2BSearch-yellowgreen)

## üìë Table of Contents

- [üìÑ Description](#-description)
  - [‚ú® Key Features](#-key-features)
- [üóÇÔ∏è Repository Structure](#-repository-structure)
- [üõ†Ô∏è Installation](#-installation)
  - [For Users](#for-users)
  - [For Developers](#for-developers)
- [üöÄ Usage & Workflow](#-usage--workflow)
- [‚öôÔ∏è Architecture](#-architecture)
- [üß™ Data‚ÄëScience Highlights](#-data-science-highlights)
- [üôå Contributing](#-contributing)
- [üë§ Author](#-author)

---

## üìÑ Description

`Insurance-LINE-Chatbot` is a production‚Äëgrade retrieval‚Äëaugmented generation (RAG) service that powers a LINE messaging chatbot for an insurance provider.  It combines modern **FastAPI** web services, **asynchronous concurrency**, **vector search** over Azure Cognitive Search and **large‚Äëlanguage models** (OpenAI &¬†Google¬†Gemini) to deliver up‚Äëto‚Äëdate answers from internal knowledge bases.  Conversations are cached for seamless multi‚Äëturn interactions and stored for analytics.

The pipeline works as follows:

1. **Message buffering.**  Incoming LINE messages are stored in a **memcached** buffer for a configurable window.  This prevents spamming the API when users type multiple messages quickly.  The webhook initialises a thread pool and retrieves a memcache client from `utils.cache.get_memcache()`.
2. **Intent classification.**  When the buffer expires, the concatenated user messages are classified using a small logistic‚Äëregression model or a prompt‚Äëengineered Gemini classifier.  The classifier labels queries as `INSURANCE_SERVICE`, `INSURANCE_PRODUCT`, `CONTINUE CONVERSATION`, `MORE` or `OFF‚ÄëTOPIC` with detailed guidelines and examples.
3. **Vector retrieval.**  Based on the predicted label, the API issues a **vector search** against either a service index (3 documents) or a product index (7¬†documents).  The thread‚Äësafe Azure Cognitive Search clients are created on demand in `utils/clients.py`.
4. **Answer generation.**  The retrieved context, conversation history and user question are passed to an LLM (OpenAI/Gemini) with a system prompt that forbids hallucination.  Predefined FAQs are served instantly from a cache.
5. **Reply and persistence.**  The answer is sent back through the LINE Messaging API with quick‚Äëreply buttons.  Conversation turns and the chosen path are saved in MongoDB for future context and analytics.

### ‚ú® Key Features

- **Retrieval‚Äëaugmented generation:** Combines document retrieval with LLM‚Äëpowered answer synthesis.
- **Intent classification:** Uses both prompt‚Äëengineered classification and a logistic‚Äëregression model to decide the retrieval path.
- **Asynchronous FastAPI:** High throughput via `asyncio`, a shared thread pool and an HTTPX async client with retry logic.
- **Stateful conversations:** Memcached buffers group messages; MongoDB stores chat history and path decisions.
- **Pluggable clients:** Modular functions create Azure Search, OpenAI, Gemini and LINE API clients.
- **Multilingual support:** Prompts include Thai and English examples for clear classification and responses.

---

## üóÇÔ∏è Repository Structure

```mermaid
graph TD
    A[Project Root] --> B(api_webhook.py)
    A --> C(utils/)
    C --> C1[clients.py]
    C --> C2[cache.py]
    C --> C3[chat_history_func.py]
    C --> C4[rag_func.py]
    A --> D[decide_path_lr.joblib]
    A --> E[requirements.txt]
    A --> F[icon_pic/]
```

| Path                         | Description                                                                                                                                                                          |
| ---------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `api_webhook.py`             | Main FastAPI application.  Handles the LINE webhook, buffers messages, runs the RAG pipeline and replies via the LINE API.  Contains FAQ answers and quick‚Äëreply button definitions. |
| `utils/clients.py`           | Factories for Azure Search, OpenAI/Gemini and LINE API clients.                                                                                                                      |
| `utils/cache.py`             | Memcached client using environment variables.                                                                                                                                        |
| `utils/chat_history_func.py` | Retrieves, summarises and persists chat history in MongoDB.                                                                                                                          |
| `utils/rag_func.py`          | Contains classification prompts, response prompts and functions to decide the retrieval path, summarise context, search and generate answers.                                        |
| `decide_path_lr.joblib`      | Logistic‚Äëregression model to classify user queries into retrieval paths.                                                                                                             |
| `icon_pic/`                  | PNG icons used in quick‚Äëreply buttons.                                                                                                                                               |
| `requirements.txt`           | Python dependencies.                                                                                                                                                                 |
---

## üõ†Ô∏è Installation

**For Users** 

<pre> ```bash pip install -r requirements.txt ``` </pre>

Create a .env file and set your LINE credentials (LINE_CHANNEL_SECRET, LINE_CHANNEL_ACCESS_TOKEN), Azure Search keys (AZURE_SEARCH_ENDPOINT, AZURE_SEARCH_KEY, AZURE_SEARCH_INDEX, AZURE_SEARCH_INDEX_INSURANCE_SERVICE), OpenAI/Gemini API keys, memcached connection parameters and MongoDB connection strings. Then run:

<pre> ```bash uvicorn api_webhook:app --host 0.0.0.0 --port 8000 ``` </pre>

Expose /callback to your LINE bot‚Äôs webhook URL.



